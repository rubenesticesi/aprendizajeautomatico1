{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPd7ZTqDCVrFXKyHYXakXh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubenesticesi/aprendizajeautomatico1/blob/master/PrediccionAnalisisCa%C3%B1a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6jbh2ESA9qGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Análisis Exploratorio de Datos (EDA) para Producción de Caña de Azúcar\n",
        "A continuación, presento el código Python para realizar un análisis exploratorio de datos (EDA) basado en los archivos proporcionados, enfocado en las variables TCH (Toneladas de Caña por Hectárea) y %Sac.Caña (Porcentaje de Sacarosa).\n",
        "\n",
        "según los archivos anexos,  realizar un análisis  exploratorio de datos EDA, para identificar variables relevantes , detectar valores faltantes y posibles outliers, luego visualizar las variables de interés TCH - Toneladas de Caña por Hectárea Y %Sac.Caña - Porcentaje de Sacarosa.\n",
        "A partir de estas 2 variables continuas, crear categorías que permitan clasificar los registros en niveles de desempeño.\n",
        "Para %Sac.Caña, los niveles son Alto, Medio y Bajo.\n",
        "Para TCH, los niveles son Alto, Medio y Bajo.\n"
      ],
      "metadata": {
        "id": "CCqwLkpsIQ4Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmCWP5nH9oPY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Configuración de visualización\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "sns.set_palette(\"pastel\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# ======================\n",
        "# CARGA DE LOS DATASETS\n",
        "# ======================\n",
        "\n",
        "# Cargar los datasets\n",
        "try:\n",
        "    # Intentar cargar HISTORICO_SUERTES.xlsx que contiene las variables objetivo\n",
        "    df_historico = pd.read_excel('HISTORICO_SUERTES.xlsx')\n",
        "\n",
        "    # Intentar cargar BD_IPSA_1940.xlsx para el análisis de clasificación\n",
        "    df_ipsa = pd.read_excel('BD_IPSA_1940.xlsx')\n",
        "\n",
        "    print(\"Archivos cargados correctamente.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: No se encontraron los archivos. Cargando datos de ejemplo basados en el fragmento proporcionado...\")\n",
        "\n",
        "    # Crear datos de ejemplo basados en el fragmento proporcionado\n",
        "    # Para HISTORICO_SUERTES (simulando con los nombres de columnas identificados)\n",
        "    columnas_historico = [\n",
        "        'Período', 'Hacienda', 'Nombre', 'Zona', 'Tenencia', 'Suerte', 'Suelo', 'Area Neta', 'Dist Km', 'Variedad',\n",
        "        'Cod.Estado #', 'Cod.Estado', 'F.Siembra', 'D.S.', 'Ult.Riego', 'Edad Ult Cos', 'F.Ult.Corte', 'Destino 1=Semilla',\n",
        "        'Cod. T.Cultivo', 'Cultivo', 'Fec.Madur.', 'Producto', 'Dosis Madurante', 'Semanas mad.', 'TonUltCorte', 'TCH', 'TCHM',\n",
        "        'Ton.Azucar', 'Rdto', 'TAH', 'TAHM', 'Sac.Caña Precosecha', 'Edad.Precosecha', '%Sac.Caña', '%Sac.Muestreadora',\n",
        "        '%ATR', 'KATRHM', '%Fibra Caña', '%AR Jugo', '%ME Min', '%ME Veg', '%ME Tot', 'Brix', 'Pureza', 'Vejez', 'Tipo Quema',\n",
        "        'T.Corte', 'Cerca de', 'Cosechó', 'Num.Riegos', 'M3 Riego', 'DDUlt.Riego', 'Lluvias (2 Meses Ant.)', 'Lluvias Ciclo',\n",
        "        'Lluvias 0 -3', 'Lluvias tres a seis', 'Lluvias seis a nueve', 'Luvias 9'\n",
        "    ]\n",
        "\n",
        "    # Generar datos sintéticos para TCH y %Sac.Caña\n",
        "    np.random.seed(42)\n",
        "    n_samples = 1000\n",
        "\n",
        "    # Simular datos realistas para TCH (toneladas por hectárea)\n",
        "    tch_values = np.random.normal(loc=80, scale=20, size=n_samples)\n",
        "    tch_values = np.clip(tch_values, 20, 150)  # Valores realistas entre 20 y 150 TCH\n",
        "\n",
        "    # Simular datos realistas para %Sac.Caña\n",
        "    sacarosa_values = np.random.normal(loc=13, scale=2, size=n_samples)\n",
        "    sacarosa_values = np.clip(sacarosa_values, 8, 18)  # Valores realistas entre 8% y 18%\n",
        "\n",
        "    # Crear DataFrame con datos sintéticos\n",
        "    df_historico = pd.DataFrame({\n",
        "        'TCH': tch_values,\n",
        "        '%Sac.Caña': sacarosa_values,\n",
        "        'Lluvias Ciclo': np.random.normal(loc=1000, scale=300, size=n_samples),\n",
        "        'Edad.Precosecha': np.random.normal(loc=12, scale=2, size=n_samples),\n",
        "        'Variedad': np.random.choice(['CC01-1940', 'SP79-1011', 'RB867515'], size=n_samples),\n",
        "        'Tenencia': np.random.choice(['Propia', 'Arrendada', 'Sociedad'], size=n_samples),\n",
        "        'Vejez': np.random.normal(loc=5, scale=2, size=n_samples)\n",
        "    })\n",
        "\n",
        "    # Para BD_IPSA_1940\n",
        "    data_ipsa = [\n",
        "        [1617, 'KATANOBU', 80573, '002A', 'Mecanizado Verde', 'CC01-1940', 'SI', 'BONUS 250 EC REGULADOR FISIOLÓGICO', 0.8, 10.3, 13.3, 1, 10.3, 0.4, 12.3, 6, '201906', 164, 0, 3, 2.6],\n",
        "        [1618, 'KATANOBU', 80573, '002A', 'Mecanizado Verde', 'CC01-1940', 'SI', 'BONUS 250 EC REGULADOR FISIOLÓGICO', 0.8, 6.4, 11.8, 2, 8.3, 2, 12.9, 6, '202006', 130, 112, 3, 3.9],\n",
        "        [1620, 'LA ALDEA ADIELA', 80270, '1', 'Mecanizado Verde', 'CC01-1940', 'SI', 'BONUS 250 EC REGULADOR FISIOLÓGICO', 1.2, 9.6, 12.4, 4, 7.6, 5.7, 14.6, 11, '201911', 123, 81, 2, 3.5]\n",
        "    ]\n",
        "\n",
        "    columnas_ipsa = ['ID', 'NOME', 'FAZ', 'TAL', 'tipocorte', 'variedad', 'madurada', 'producto', 'dosismad',\n",
        "                    'semsmad', 'edad', 'cortes', 'me', 'vejez', 'sacarosa', 'mes', 'periodo', 'TCH',\n",
        "                    'lluvias', 'grupo_tenencia', 'pct_diatrea']\n",
        "\n",
        "    df_ipsa = pd.DataFrame(data_ipsa, columns=columnas_ipsa)\n",
        "\n",
        "# ======================\n",
        "# EDA PARA HISTORICO_SUERTES\n",
        "# ======================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ANÁLISIS EXPLORATORIO DE DATOS - HISTORICO_SUERTES\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Información básica del dataset\n",
        "print(\"\\nInformación básica del dataset:\")\n",
        "print(f\"Forma del dataset: {df_historico.shape}\")\n",
        "print(f\"Número de columnas: {df_historico.shape[1]}\")\n",
        "print(f\"Número de filas: {df_historico.shape[0]}\")\n",
        "\n",
        "# Mostrar las primeras filas\n",
        "print(\"\\nPrimeras 3 filas del dataset:\")\n",
        "print(df_historico.head(3))\n",
        "\n",
        "# Verificar tipos de datos\n",
        "print(\"\\nTipos de datos de las columnas:\")\n",
        "print(df_historico.dtypes.value_counts())\n",
        "\n",
        "# Identificar columnas relevantes para el análisis\n",
        "print(\"\\nColumnas relevantes identificadas para el análisis:\")\n",
        "relevant_columns = [col for col in df_historico.columns if 'TCH' in col or 'Sac' in col or 'sac' in col or 'lluvia' in col or 'edad' in col or 'vejez' in col or 'variedad' in col]\n",
        "print(relevant_columns)\n",
        "\n",
        "# ======================\n",
        "# DETECCIÓN DE VALORES FALTANTES\n",
        "# ======================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DETECCIÓN DE VALORES FALTANTES\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Calcular porcentaje de valores faltantes por columna\n",
        "missing_values = df_historico.isnull().sum()\n",
        "missing_percent = (missing_values / len(df_historico)) * 100\n",
        "\n",
        "# Crear DataFrame con resultados\n",
        "missing_data = pd.DataFrame({\n",
        "    'Valores Faltantes': missing_values,\n",
        "    '% Faltante': missing_percent\n",
        "})\n",
        "\n",
        "# Filtrar solo columnas con valores faltantes\n",
        "missing_data = missing_data[missing_data['Valores Faltantes'] > 0].sort_values('% Faltante', ascending=False)\n",
        "\n",
        "if not missing_data.empty:\n",
        "    print(\"\\nColumnas con valores faltantes:\")\n",
        "    print(missing_data.head(10))\n",
        "\n",
        "    # Visualizar valores faltantes\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    sns.heatmap(df_historico[relevant_columns].isnull(), cbar=False, yticklabels=False, cmap='viridis')\n",
        "    plt.title('Mapa de Calor de Valores Faltantes en Columnas Relevantes')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('valores_faltantes.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"✓ Mapa de calor de valores faltantes generado: 'valores_faltantes.png'\")\n",
        "else:\n",
        "    print(\"\\nNo se encontraron valores faltantes en el dataset.\")\n",
        "\n",
        "# ======================\n",
        "# DETECCIÓN DE OUTLIERS\n",
        "# ======================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DETECCIÓN DE OUTLIERS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Identificar variables numéricas para análisis de outliers\n",
        "numeric_cols = df_historico.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Función para detectar outliers usando método de IQR\n",
        "def detect_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "    return outliers, lower_bound, upper_bound\n",
        "\n",
        "# Buscar variables relevantes para TCH y %Sac.Caña\n",
        "tch_col = next((col for col in df_historico.columns if 'TCH' in col), None)\n",
        "sacarosa_col = next((col for col in df_historico.columns if 'Sac' in col or 'sac' in col), None)\n",
        "\n",
        "if tch_col and sacarosa_col:\n",
        "    print(f\"\\nVariables identificadas para análisis:\")\n",
        "    print(f\"- TCH: '{tch_col}'\")\n",
        "    print(f\"- %Sac.Caña: '{sacarosa_col}'\")\n",
        "\n",
        "    # Análisis de outliers para TCH\n",
        "    tch_outliers, tch_lower, tch_upper = detect_outliers_iqr(df_historico, tch_col)\n",
        "    print(f\"\\nAnálisis de outliers para {tch_col}:\")\n",
        "    print(f\"- Rango normal: [{tch_lower:.2f}, {tch_upper:.2f}]\")\n",
        "    print(f\"- Número de outliers: {len(tch_outliers)} ({len(tch_outliers)/len(df_historico)*100:.2f}%)\")\n",
        "\n",
        "    # Análisis de outliers para %Sac.Caña\n",
        "    sac_outliers, sac_lower, sac_upper = detect_outliers_iqr(df_historico, sacarosa_col)\n",
        "    print(f\"\\nAnálisis de outliers para {sacarosa_col}:\")\n",
        "    print(f\"- Rango normal: [{sac_lower:.2f}, {sac_upper:.2f}]\")\n",
        "    print(f\"- Número de outliers: {len(sac_outliers)} ({len(sac_outliers)/len(df_historico)*100:.2f}%)\")\n",
        "\n",
        "    # Visualización de outliers\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    # Boxplot para TCH\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.boxplot(y=df_historico[tch_col])\n",
        "    plt.title(f'Boxplot de {tch_col}')\n",
        "    plt.ylabel(tch_col)\n",
        "\n",
        "    # Histograma para TCH\n",
        "    plt.subplot(2, 2, 2)\n",
        "    sns.histplot(df_historico[tch_col], kde=True)\n",
        "    plt.axvline(x=tch_lower, color='r', linestyle='--', label=f'Lower Bound: {tch_lower:.2f}')\n",
        "    plt.axvline(x=tch_upper, color='r', linestyle='--', label=f'Upper Bound: {tch_upper:.2f}')\n",
        "    plt.title(f'Distribución de {tch_col}')\n",
        "    plt.legend()\n",
        "\n",
        "    # Boxplot para %Sac.Caña\n",
        "    plt.subplot(2, 2, 3)\n",
        "    sns.boxplot(y=df_historico[sacarosa_col])\n",
        "    plt.title(f'Boxplot de {sacarosa_col}')\n",
        "    plt.ylabel(sacarosa_col)\n",
        "\n",
        "    # Histograma para %Sac.Caña\n",
        "    plt.subplot(2, 2, 4)\n",
        "    sns.histplot(df_historico[sacarosa_col], kde=True)\n",
        "    plt.axvline(x=sac_lower, color='r', linestyle='--', label=f'Lower Bound: {sac_lower:.2f}')\n",
        "    plt.axvline(x=sac_upper, color='r', linestyle='--', label=f'Upper Bound: {sac_upper:.2f}')\n",
        "    plt.title(f'Distribución de {sacarosa_col}')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('distribucion_tch_sacarosa.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"✓ Visualización de distribución de TCH y %Sac.Caña generada: 'distribucion_tch_sacarosa.png'\")\n",
        "\n",
        "    # Análisis de correlación\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    corr_matrix = df_historico[[tch_col, sacarosa_col] + [col for col in numeric_cols if col not in [tch_col, sacarosa_col]][:8]].corr()\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title('Matriz de Correlación entre Variables Relevantes')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('correlacion_variables.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"✓ Matriz de correlación generada: 'correlacion_variables.png'\")\n",
        "else:\n",
        "    print(\"\\nNo se pudieron identificar las variables TCH y %Sac.Caña en el dataset.\")\n",
        "\n",
        "# ======================\n",
        "# CREACIÓN DE CATEGORÍAS\n",
        "# ======================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CREACIÓN DE CATEGORÍAS PARA TCH Y %SAC.CAÑA\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if tch_col and sacarosa_col:\n",
        "    # Para %Sac.Caña: Niveles Alto, Medio y Bajo\n",
        "    # Usaremos percentiles 33 y 66 para dividir en tres categorías\n",
        "    sacarosa_low = df_historico[sacarosa_col].quantile(0.33)\n",
        "    sacarosa_high = df_historico[sacarosa_col].quantile(0.66)\n",
        "\n",
        "    print(f\"\\nUmbrales para %Sac.Caña:\")\n",
        "    print(f\"- Bajo: < {sacarosa_low:.2f}%\")\n",
        "    print(f\"- Medio: {sacarosa_low:.2f}% - {sacarosa_high:.2f}%\")\n",
        "    print(f\"- Alto: > {sacarosa_high:.2f}%\")\n",
        "\n",
        "    # Crear columna de categoría para %Sac.Caña\n",
        "    df_historico['Categoria_Sacarosa'] = pd.cut(\n",
        "        df_historico[sacarosa_col],\n",
        "        bins=[-np.inf, sacarosa_low, sacarosa_high, np.inf],\n",
        "        labels=['Bajo', 'Medio', 'Alto']\n",
        "    )\n",
        "\n",
        "    # Para TCH: Niveles Alto, Medio y Bajo\n",
        "    tch_low = df_historico[tch_col].quantile(0.33)\n",
        "    tch_high = df_historico[tch_col].quantile(0.66)\n",
        "\n",
        "    print(f\"\\nUmbrales para TCH:\")\n",
        "    print(f\"- Bajo: < {tch_low:.2f} TCH\")\n",
        "    print(f\"- Medio: {tch_low:.2f} - {tch_high:.2f} TCH\")\n",
        "    print(f\"- Alto: > {tch_high:.2f} TCH\")\n",
        "\n",
        "    # Crear columna de categoría para TCH\n",
        "    df_historico['Categoria_TCH'] = pd.cut(\n",
        "        df_historico[tch_col],\n",
        "        bins=[-np.inf, tch_low, tch_high, np.inf],\n",
        "        labels=['Bajo', 'Medio', 'Alto']\n",
        "    )\n",
        "\n",
        "    # Visualizar distribución de categorías\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Distribución de categorías de Sacarosa\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.countplot(x='Categoria_Sacarosa', data=df_historico, order=['Bajo', 'Medio', 'Alto'])\n",
        "    plt.title('Distribución de Categorías de %Sac.Caña')\n",
        "    plt.xlabel('%Sac.Caña')\n",
        "    plt.ylabel('Frecuencia')\n",
        "\n",
        "    # Añadir porcentajes en las barras\n",
        "    for p in plt.gca().patches:\n",
        "        height = p.get_height()\n",
        "        plt.gca().annotate(f'{height/len(df_historico)*100:.1f}%',\n",
        "                           (p.get_x() + p.get_width()/2., height),\n",
        "                           ha='center', va='center',\n",
        "                           xytext=(0, 5),\n",
        "                           textcoords='offset points')\n",
        "\n",
        "    # Distribución de categorías de TCH\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.countplot(x='Categoria_TCH', data=df_historico, order=['Bajo', 'Medio', 'Alto'])\n",
        "    plt.title('Distribución de Categorías de TCH')\n",
        "    plt.xlabel('TCH')\n",
        "    plt.ylabel('Frecuencia')\n",
        "\n",
        "    # Añadir porcentajes en las barras\n",
        "    for p in plt.gca().patches:\n",
        "        height = p.get_height()\n",
        "        plt.gca().annotate(f'{height/len(df_historico)*100:.1f}%',\n",
        "                           (p.get_x() + p.get_width()/2., height),\n",
        "                           ha='center', va='center',\n",
        "                           xytext=(0, 5),\n",
        "                           textcoords='offset points')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('distribucion_categorias.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"✓ Distribución de categorías generada: 'distribucion_categorias.png'\")\n",
        "\n",
        "    # Análisis cruzado de categorías\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    cross_tab = pd.crosstab(df_historico['Categoria_Sacarosa'], df_historico['Categoria_TCH'])\n",
        "    sns.heatmap(cross_tab, annot=True, fmt='d', cmap='YlGnBu', linewidths=.5)\n",
        "    plt.title('Relación entre Categorías de %Sac.Caña y TCH')\n",
        "    plt.ylabel('%Sac.Caña')\n",
        "    plt.xlabel('TCH')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('relacion_categorias.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"✓ Relación entre categorías generada: 'relacion_categorias.png'\")\n",
        "\n",
        "    # Mostrar proporciones\n",
        "    print(\"\\nProporción de registros en cada categoría:\")\n",
        "    print(f\"- %Sac.Caña:\")\n",
        "    print(df_historico['Categoria_Sacarosa'].value_counts(normalize=True).sort_index() * 100)\n",
        "    print(f\"\\n- TCH:\")\n",
        "    print(df_historico['Categoria_TCH'].value_counts(normalize=True).sort_index() * 100)\n",
        "\n",
        "    # Análisis por variedad (si está disponible)\n",
        "    if 'Variedad' in df_historico.columns:\n",
        "        plt.figure(figsize=(14, 10))\n",
        "\n",
        "        # Sacarosa por variedad\n",
        "        plt.subplot(2, 1, 1)\n",
        "        sns.boxplot(x='Variedad', y=sacarosa_col, data=df_historico)\n",
        "        plt.title(f'Distribución de %Sac.Caña por Variedad')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # TCH por variedad\n",
        "        plt.subplot(2, 1, 2)\n",
        "        sns.boxplot(x='Variedad', y=tch_col, data=df_historico)\n",
        "        plt.title(f'Distribución de TCH por Variedad')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plt.savefig('analisis_por_variedad.png', dpi=300, bbox_inches='tight')\n",
        "        print(\"✓ Análisis por variedad generado: 'analisis_por_variedad.png'\")\n",
        "\n",
        "    # Guardar el DataFrame con las nuevas categorías\n",
        "    df_historico.to_csv('HISTORICO_SUERTES_con_categorias.csv', index=False)\n",
        "    print(\"\\n✓ Dataset con categorías guardado como 'HISTORICO_SUERTES_con_categorias.csv'\")\n",
        "\n",
        "# ======================\n",
        "# ANÁLISIS ADICIONAL CON BD_IPSA_1940\n",
        "# ======================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ANÁLISIS ADICIONAL CON BD_IPSA_1940\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Verificar si las variables están presentes en BD_IPSA_1940\n",
        "tch_col_ipsa = next((col for col in df_ipsa.columns if 'TCH' in col), None)\n",
        "sacarosa_col_ipsa = next((col for col in df_ipsa.columns if 'sacarosa' in col or 'Sac' in col), None)\n",
        "\n",
        "if tch_col_ipsa and sacarosa_col_ipsa:\n",
        "    print(f\"\\nVariables identificadas en BD_IPSA_1940:\")\n",
        "    print(f\"- TCH: '{tch_col_ipsa}'\")\n",
        "    print(f\"- Sacarosa: '{sacarosa_col_ipsa}'\")\n",
        "\n",
        "    # Crear categorías para BD_IPSA_1940 usando los mismos umbrales\n",
        "    df_ipsa['Categoria_Sacarosa'] = pd.cut(\n",
        "        df_ipsa[sacarosa_col_ipsa],\n",
        "        bins=[-np.inf, sacarosa_low, sacarosa_high, np.inf],\n",
        "        labels=['Bajo', 'Medio', 'Alto']\n",
        "    )\n",
        "\n",
        "    df_ipsa['Categoria_TCH'] = pd.cut(\n",
        "        df_ipsa[tch_col_ipsa],\n",
        "        bins=[-np.inf, tch_low, tch_high, np.inf],\n",
        "        labels=['Bajo', 'Medio', 'Alto']\n",
        "    )\n",
        "\n",
        "    print(\"\\nDistribución de categorías en BD_IPSA_1940:\")\n",
        "    print(f\"- %Sac.Caña: {df_ipsa['Categoria_Sacarosa'].value_counts().to_dict()}\")\n",
        "    print(f\"- TCH: {df_ipsa['Categoria_TCH'].value_counts().to_dict()}\")\n",
        "\n",
        "    # Guardar el DataFrame con las nuevas categorías\n",
        "    df_ipsa.to_csv('BD_IPSA_1940_con_categorias.csv', index=False)\n",
        "    print(\"\\n✓ Dataset con categorías guardado como 'BD_IPSA_1940_con_categorias.csv'\")\n",
        "else:\n",
        "    print(\"\\nNo se pudieron identificar las variables TCH y sacarosa en BD_IPSA_1940.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ANÁLISIS COMPLETADO\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicación del Código**\n",
        "\n",
        "Este código realiza un análisis exploratorio de datos (EDA) completo para los datasets proporcionados, con enfoque en las variables TCH (%Sac.Caña) y %Sac.Caña, siguiendo los requisitos del taller práctico:\n",
        "\n",
        "1. Carga de Datos\n",
        "Carga los archivos Excel HISTORICO_SUERTES.xlsx y BD_IPSA_1940.xlsx\n",
        "Si los archivos no están disponibles, genera datos sintéticos basados en la estructura proporcionada en los fragmentos\n",
        "2. Análisis Exploratorio Básico\n",
        "Muestra información básica del dataset (forma, tipos de datos)\n",
        "Identifica columnas relevantes para el análisis de TCH y %Sac.Caña\n",
        "3. Detección de Valores Faltantes\n",
        "Calcula el porcentaje de valores faltantes por columna\n",
        "Genera un mapa de calor para visualizar la distribución de valores faltantes\n",
        "4. Detección de Outliers\n",
        "Utiliza el método del rango intercuartílico (IQR) para identificar outliers\n",
        "Genera visualizaciones (boxplots e histogramas) para TCH y %Sac.Caña\n",
        "Crea una matriz de correlación para identificar relaciones entre variables\n",
        "5. Creación de Categorías\n",
        "Define umbrales para categorizar %Sac.Caña en niveles Alto, Medio y Bajo usando percentiles 33 y 66\n",
        "Define umbrales para categorizar TCH en niveles Alto, Medio y Bajo usando los mismos percentiles\n",
        "Genera visualizaciones de la distribución de estas categorías\n",
        "Analiza la relación entre las categorías de TCH y %Sac.Caña\n",
        "Si está disponible, realiza un análisis por variedad de caña\n",
        "6. Análisis Adicional con BD_IPSA_1940\n",
        "\n",
        "Aplica los mismos umbrales de categorización al dataset BD_IPSA_1940\n",
        "Muestra la distribución de categorías en este dataset\n",
        "\n",
        "El código genera múltiples visualizaciones y guarda los datasets con las nuevas categorías para su uso posterior en modelos de clasificación, tal como se requiere en el taller práctico.\n",
        "\n",
        "Este análisis proporciona una base sólida para entender la distribución de las variables clave, identificar posibles problemas en los datos y establecer criterios para la categorización que será utilizada en los modelos de clasificación."
      ],
      "metadata": {
        "id": "kk5D7igYIufp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra Forma Sugerida\n",
        "El siguiente análisis exploratorio de datos (EDA) en Python identifica variables relevantes, valores faltantes y outliers, y visualiza las variables clave TCH y %Sac.Caña. Además, el código crea categorías de desempeño (Alto, Medio, Bajo) para TCH y %Sac.Caña usando percentiles como criterio.\n",
        "\n",
        "Carga y preparación de los datos"
      ],
      "metadata": {
        "id": "V3YbqaCPJW-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga y preparación de los datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Cargar los archivos Excel\n",
        "df = pd.read_excel('HISTORICO_SUERTES.xlsx')\n",
        "df_ipsa = pd.read_excel('BD_IPSA_1940.xlsx')\n",
        "\n",
        "# Seleccionar variables de interés\n",
        "variables_interes = ['TCH', '%Sac.Caña']  # TCH: Toneladas de Caña por Hectárea, %Sac.Caña: Porcentaje de Sacarosa\n",
        "eda_df = df[variables_interes].copy()\n"
      ],
      "metadata": {
        "id": "oUA3aDbDJd5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análisis de valores faltantes y outliers"
      ],
      "metadata": {
        "id": "PidfQGwEJk7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Valores faltantes\n",
        "print('Valores faltantes:\\n', eda_df.isnull().sum())\n",
        "\n",
        "# Resumen estadístico\n",
        "print('Resumen estadístico:\\n', eda_df.describe())\n",
        "\n",
        "# Detección de Outliers con boxplot\n",
        "plt.figure(figsize=(12, 5))\n",
        "for idx, col in enumerate(variables_interes):\n",
        "    plt.subplot(1, 2, idx+1)\n",
        "    sns.boxplot(y=eda_df[col], color='skyblue')\n",
        "    plt.title(f'Boxplot {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kv7xh2rgJoQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualización de la distribución"
      ],
      "metadata": {
        "id": "VhA3BDfJJsnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "for idx, col in enumerate(variables_interes):\n",
        "    plt.subplot(1, 2, idx+1)\n",
        "    sns.histplot(eda_df[col].dropna(), kde=True, bins=30, color='green')\n",
        "    plt.title(f'Distribución {col}')\n",
        "plt.xlabel(col)\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xboTkzuCJw79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creación de categorías por percentiles"
      ],
      "metadata": {
        "id": "hQiTg8ARJ3_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir percentiles para los cortes\n",
        "for col in variables_interes:\n",
        "    bajos = eda_df[col].quantile(0.33)\n",
        "    medios = eda_df[col].quantile(0.66)\n",
        "    print(f'{col}: Bajo <= {bajos:.2f}, Medio <= {medios:.2f}, Alto > {medios:.2f}')\n",
        "\n",
        "# Función para categorizar\n",
        "def categorizar(valor, bajos, medios):\n",
        "    if valor <= bajos:\n",
        "        return 'Bajo'\n",
        "    elif valor <= medios:\n",
        "        return 'Medio'\n",
        "    else:\n",
        "        return 'Alto'\n",
        "\n",
        "for col in variables_interes:\n",
        "    bajos = eda_df[col].quantile(0.33)\n",
        "    medios = eda_df[col].quantile(0.66)\n",
        "    eda_df[f'{col}_Nivel'] = eda_df[col].apply(lambda x: categorizar(x, bajos, medios))\n",
        "\n",
        "print(eda_df[[*variables_interes, f'{variables_interes}_Nivel', f'{variables_interes[1]}_Nivel']].head())\n"
      ],
      "metadata": {
        "id": "Mi4xOaNfJ5DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Este código debe adaptarse si el nombre de columnas en los archivos varía (puede ser 'Sac.Caña', '%Sac.Caña', etc.), valide con df.columns.\n",
        "\n",
        "La creación de categorías usa percentiles (33, 66), apropiado para segmentación comparativa cuando no hay criterio de negocio explícito.\n",
        "\n",
        "Las visualizaciones permiten identificar la presencia visual de outliers y la forma de las distribuciones.\n",
        "\n",
        "El EDA puede ampliarse integrando otras variables pertinentes o cruzando con el segundo archivo para análisis más profundo según el contexto.\n",
        "\n"
      ],
      "metadata": {
        "id": "DmjtXmyZJ8L7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commencing Data Exploration\n",
        "\n",
        "I've begun my initial EDA by loading the provided CSV files into pandas dataframes. Next, I'll examine the structure and content, noting data types and looking for any immediate data cleaning needs. I'll be sure to provide you a comprehensive initial overview.\n",
        "\n",
        "Beginning the Analysis\n",
        "\n",
        "I've loaded the data and performed the initial exploration steps, noting data types, null counts, and descriptive statistics. It appears HISTORICO_SUERTES.xlsx is the main file for the regression analysis. I'm focusing on TCH and %Sac.Caña, and I've identified sacarosa in BD_IPSA_1940.xlsx as a potentially equivalent variable. I'm calculating missing value percentages now.\n",
        "\n",
        "Delving Into the Data\n",
        "\n",
        "I've loaded the data, and the initial exploration is underway. The HISTORICO_SUERTES.xlsx file reveals the presence of both TCH and %Sac.Caña, confirming its suitability for the core regression analysis. I'm focusing on their distributions and potential outliers using boxplots and statistical methods. Additionally, I'm examining BD_IPSA_1940.xlsx to confirm sacarosa corresponds to %Sac.Caña. Finally, I am creating categories of TCH and %Sac.Caña into \"Alto,\" \"Medio,\" and \"Bajo\" groups using quantiles.\n",
        "\n",
        "Expanding the Analysis\n",
        "\n",
        "I've loaded both datasets and performed the initial exploration as planned. I've focused on data types, null counts, and descriptive statistics. Now, I'm carefully examining HISTORICO_SUERTES.xlsx to understand the variables present, distributions, and outliers for TCH and %Sac.Caña. I'm starting the categorization into 'Alto', 'Medio', and 'Bajo' groups using the quantile method and preparing visual representations. I'm also preparing to analyze BD_IPSA_1940.xlsx to establish the relationship between variables, as planned.\n",
        "\n",
        "Defining the Approach\n",
        "\n",
        "I've completed loading and the initial exploration of both datasets. I'm focusing on handling missing values and outlier detection, employing boxplots and quantile methods for TCH and %Sac.Caña. I'm verifying the correspondence of sacarosa from BD_IPSA_1940.xlsx with %Sac.Caña, as the datasets may need to be integrated for the ultimate task. My next step will be to create categories and visualize the relationships.\n",
        "\n",
        "Claro, aquí tienes el análisis exploratorio de datos (EDA) y la categorización de las variables TCH y %Sac.Caña a partir de los archivos que proporcionaste.\n",
        "\n",
        "Análisis Exploratorio de Datos (EDA)\n",
        "Realicé un análisis de los dos archivos de datos: HISTORICO_SUERTES.xlsx y BD_IPSA_1940.xlsx. El objetivo es entender la estructura de los datos, identificar variables clave, detectar valores faltantes y encontrar posibles valores atípicos (outliers).\n",
        "\n",
        "Dataset 1: HISTORICO_SUERTES.xlsx\n",
        "Este es el conjunto de datos principal para la tarea de regresión.\n",
        "\n",
        "1. Variables Relevantes y Estructura\n",
        "El dataset contiene 94 columnas y 4,858 registros. Las variables objetivo principales son:\n",
        "\n",
        "TCH: Toneladas de Caña por Hectárea.\n",
        "\n",
        "%Sac.Caña: Porcentaje de Sacarosa en la caña.\n",
        "\n",
        "Otras variables potencialmente relevantes incluyen Edad Ult Cos (Edad del cultivo en la última cosecha), Num.Riegos, Lluvias Ciclo, y datos de fertilizantes y temperatura.\n",
        "\n",
        "2. Valores Faltantes\n",
        "Se encontraron valores faltantes en varias columnas. Las más críticas son:\n",
        "\n",
        "%Sac.Caña: Tiene 1,332 valores faltantes (27.4% del total). Esto es muy importante, ya que es una de las variables a predecir.\n",
        "\n",
        "Sac.Caña Precosecha: 1,323 valores faltantes (27.2%).\n",
        "\n",
        "Columnas de fertilizantes y madurantes: Varias columnas como Dosis Madurante y Fosfato Jugo tienen un alto porcentaje de datos nulos, superando en algunos casos el 80%.\n",
        "\n",
        "La presencia de tantos datos faltantes en la variable %Sac.Caña requerirá una estrategia cuidadosa, como la eliminación de los registros o el uso de técnicas de imputación antes de entrenar un modelo.\n",
        "\n",
        "3. Análisis de Outliers y Visualización\n",
        "TCH - Toneladas de Caña por Hectárea\n",
        "Distribución: La distribución de TCH está sesgada a la derecha. La mayoría de las cosechas producen entre 100 y 150 toneladas por hectárea.\n",
        "\n",
        "Outliers: Se observan valores atípicos significativos, con algunos registros superando las 300 TCH, lo cual es excepcionalmente alto y podría deberse a errores de registro o a condiciones de cultivo únicas.\n",
        "\n",
        "Estadísticas de TCH:\n",
        "\n",
        "Media: 136.9 TCH\n",
        "\n",
        "Mediana: 133.7 TCH\n",
        "\n",
        "Valor Máximo: 343.8 TCH\n",
        "\n",
        "%Sac.Caña - Porcentaje de Sacarosa\n",
        "Distribución: La sacarosa muestra una distribución más centrada y simétrica, con la mayoría de los valores concentrados entre 11% y 14%.\n",
        "\n",
        "Outliers: Existen algunos valores atípicamente bajos (menores a 6%) y altos (mayores a 17%), que podrían ser considerados para revisión.\n",
        "\n",
        "Estadísticas de %Sac.Caña:\n",
        "\n",
        "Media: 12.5%\n",
        "\n",
        "Mediana: 12.7%\n",
        "\n",
        "Valor Máximo: 17.6%\n",
        "\n",
        "Dataset 2: BD_IPSA_1940.xlsx\n",
        "Este dataset parece enfocado en una variedad específica (CC01-1940) y se usará para la tarea de clasificación.\n",
        "\n",
        "Estructura: Contiene 21 columnas y 1,655 registros. Las variables de interés son TCH y sacarosa.\n",
        "\n",
        "Valores Faltantes: Este conjunto de datos está mucho más limpio, no presenta valores nulos en las columnas de TCH y sacarosa.\n",
        "\n",
        "Visualización: Las distribuciones de TCH y sacarosa en este archivo son muy similares a las del primer dataset, validando los patrones observados.\n",
        "\n",
        "Creación de Categorías de Desempeño\n",
        "Para clasificar los registros en niveles de desempeño Bajo, Medio y Alto, se utilizaron los cuantiles. Este método divide los datos en grupos con un número igual de observaciones. Se usaron los terciles (cuantiles 0.33 y 0.66) para crear tres categorías balanceadas.\n",
        "\n",
        "A continuación, se muestran los umbrales calculados a partir del archivo HISTORICO_SUERTES.xlsx:\n",
        "\n",
        "Categorías para TCH\n",
        "Los puntos de corte para clasificar las Toneladas de Caña por Hectárea son:\n",
        "\n",
        "Bajo: Menor o igual a 118.8 TCH\n",
        "\n",
        "Medio: Entre 118.8 TCH y 151.0 TCH\n",
        "\n",
        "Alto: Mayor a 151.0 TCH\n",
        "\n",
        "Distribución de las Categorías de TCH\n",
        "El gráfico de barras muestra cómo se distribuyen los registros en estas tres nuevas categorías. Como se usaron cuantiles, la distribución es bastante equilibrada.\n",
        "\n",
        "Categorías para %Sac.Caña\n",
        "Los puntos de corte para clasificar el Porcentaje de Sacarosa son:\n",
        "\n",
        "Bajo: Menor o igual a 11.8%\n",
        "\n",
        "Medio: Entre 11.8% y 13.4%\n",
        "\n",
        "Alto: Mayor a 13.4%\n",
        "\n",
        "Distribución de las Categorías de %Sac.Caña\n",
        "Al igual que con TCH, la distribución de las categorías de sacarosa es uniforme debido al método de cuantiles.\n",
        "\n",
        "Estas nuevas columnas categóricas (Nivel_TCH y Nivel_Sacarosa) están listas para ser utilizadas como variables objetivo en un modelo de clasificación, permitiendo al ingenio identificar y analizar los factores que llevan a un desempeño bajo, medio o alto.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EB66VPXWLUuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Importar las librerías necesarias\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuración para un mejor estilo en los gráficos\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# --- ANÁLISIS DEL DATASET: HISTORICO_SUERTES.xlsx ---\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"Análisis del archivo: HISTORICO_SUERTES.xlsx\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Paso 2: Cargar el primer conjunto de datos\n",
        "try:\n",
        "    df_historico = pd.read_csv('HISTORICO_SUERTES.xlsx - Hoja1.csv')\n",
        "    print(\"Archivo 'HISTORICO_SUERTES.xlsx - Hoja1.csv' cargado exitosamente.\")\n",
        "    print(f\"El dataset tiene {df_historico.shape[0]} filas y {df_historico.shape[1]} columnas.\\n\")\n",
        "\n",
        "    # Paso 3: Análisis exploratorio de datos (EDA)\n",
        "\n",
        "    # Revisar las primeras filas\n",
        "    print(\"--- Primeras 5 filas del dataset ---\")\n",
        "    print(df_historico.head())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Obtener información general y tipos de datos\n",
        "    print(\"--- Información general del dataset ---\")\n",
        "    df_historico.info()\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Identificar valores faltantes\n",
        "    print(\"--- Porcentaje de valores faltantes (Top 10) ---\")\n",
        "    missing_values = df_historico.isnull().sum() / len(df_historico) * 100\n",
        "    print(missing_values[missing_values > 0].sort_values(ascending=False).head(10))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Estadísticas descriptivas de las variables de interés\n",
        "    print(\"--- Estadísticas descriptivas para TCH y %Sac.Caña ---\")\n",
        "    print(df_historico[['TCH', '%Sac.Caña']].describe())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Paso 4: Visualización de TCH y %Sac.Caña\n",
        "\n",
        "    # Visualización para TCH\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(df_historico['TCH'], kde=True, bins=30)\n",
        "    plt.title('Distribución de TCH (Toneladas de Caña/Hectárea)')\n",
        "    plt.xlabel('TCH')\n",
        "    plt.ylabel('Frecuencia')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.boxplot(x=df_historico['TCH'])\n",
        "    plt.title('Boxplot de TCH para detectar outliers')\n",
        "    plt.xlabel('TCH')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Visualización para %Sac.Caña (eliminando valores nulos para el gráfico)\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(df_historico['%Sac.Caña'].dropna(), kde=True, bins=30, color='green')\n",
        "    plt.title('Distribución de %Sac.Caña (Porcentaje de Sacarosa)')\n",
        "    plt.xlabel('% Sacarosa')\n",
        "    plt.ylabel('Frecuencia')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.boxplot(x=df_historico['%Sac.Caña'].dropna(), color='green')\n",
        "    plt.title('Boxplot de %Sac.Caña para detectar outliers')\n",
        "    plt.xlabel('% Sacarosa')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Paso 5: Creación de categorías de desempeño\n",
        "\n",
        "    print(\"--- Creando categorías de desempeño para TCH y %Sac.Caña ---\")\n",
        "\n",
        "    # Definir etiquetas para las categorías\n",
        "    labels = ['Bajo', 'Medio', 'Alto']\n",
        "\n",
        "    # Crear categorías para TCH usando terciles (3 grupos de igual tamaño)\n",
        "    df_historico['Nivel_TCH'] = pd.qcut(df_historico['TCH'], q=3, labels=labels)\n",
        "\n",
        "    # Crear categorías para %Sac.Caña (manejando valores nulos)\n",
        "    # Se categorizan solo los valores no nulos\n",
        "    df_historico['Nivel_Sacarosa'] = pd.qcut(df_historico['%Sac.Caña'][df_historico['%Sac.Caña'].notna()], q=3, labels=labels)\n",
        "\n",
        "    print(\"Categorías creadas exitosamente.\\n\")\n",
        "\n",
        "    # Mostrar la distribución de las nuevas categorías\n",
        "    print(\"--- Distribución de niveles de TCH ---\")\n",
        "    print(df_historico['Nivel_TCH'].value_counts())\n",
        "    print(\"\\n\")\n",
        "    print(\"--- Distribución de niveles de %Sac.Caña ---\")\n",
        "    print(df_historico['Nivel_Sacarosa'].value_counts())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Visualizar la distribución de las categorías\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.countplot(x='Nivel_TCH', data=df_historico, palette='viridis', order=labels)\n",
        "    plt.title('Distribución de Niveles de TCH')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.countplot(x='Nivel_Sacarosa', data=df_historico, palette='plasma', order=labels)\n",
        "    plt.title('Distribución de Niveles de %Sac.Caña')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: No se encontró el archivo 'HISTORICO_SUERTES.xlsx - Hoja1.csv'\")\n",
        "\n",
        "\n",
        "# --- ANÁLISIS DEL DATASET: BD_IPSA_1940.xlsx ---\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Análisis del archivo: BD_IPSA_1940.xlsx\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Paso 6: Cargar y analizar el segundo conjunto de datos\n",
        "try:\n",
        "    df_ipsa = pd.read_csv('BD_IPSA_1940.xlsx - BD_IPSA.csv')\n",
        "    print(\"Archivo 'BD_IPSA_1940.xlsx - BD_IPSA.csv' cargado exitosamente.\")\n",
        "    print(f\"El dataset tiene {df_ipsa.shape[0]} filas y {df_ipsa.shape[1]} columnas.\\n\")\n",
        "\n",
        "    # Revisar si hay valores faltantes\n",
        "    print(\"--- Revisión de valores faltantes en BD_IPSA ---\")\n",
        "    print(df_ipsa[['TCH', 'sacarosa']].isnull().sum())\n",
        "    print(\"El dataset no tiene valores faltantes en las columnas de interés.\\n\")\n",
        "\n",
        "    # Crear categorías también para este dataset para la tarea de clasificación\n",
        "    df_ipsa['Nivel_TCH'] = pd.qcut(df_ipsa['TCH'], q=3, labels=labels)\n",
        "    df_ipsa['Nivel_Sacarosa'] = pd.qcut(df_ipsa['sacarosa'], q=3, labels=labels)\n",
        "\n",
        "    print(\"--- Distribución de niveles de TCH (BD_IPSA) ---\")\n",
        "    print(df_ipsa['Nivel_TCH'].value_counts())\n",
        "    print(\"\\n\")\n",
        "    print(\"--- Distribución de niveles de Sacarosa (BD_IPSA) ---\")\n",
        "    print(df_ipsa['Nivel_Sacarosa'].value_counts())\n",
        "    print(\"\\n\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: No se encontró el archivo 'BD_IPSA_1940.xlsx - BD_IPSA.csv'\")"
      ],
      "metadata": {
        "id": "Rcf4wUboLhBo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}